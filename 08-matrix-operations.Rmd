# Matrix Operations

In this chapter you will learn about some of the common arithmetic operations (addition, subtraction, and multiplication) that can be performed with matrices.


## Matrix Addition and Subtraction

Two or more matrices can be added or subtracted if they have the same dimensions; if not, matrix addition and subtraction is undefined. Just as in vector addition, each corresponding element is added or subtracted and placed in the corresponding location in the new matrix. Consider the following two matrices:

$$
\mathbf{A} = \begin{bmatrix}
112 & 86 & 0 \\ 134 & 94 & 0
\end{bmatrix} \qquad 
\mathbf{B} = \begin{bmatrix}
101 & 89 & 1 \\110 & 90 & 0
\end{bmatrix}
$$

Then

$$
\begin{split}
\mathbf{A} + \mathbf{B} &= \begin{bmatrix}
112 & 86 & 0 \\ 134 & 94 & 0
\end{bmatrix} + \begin{bmatrix}
101 & 89 & 1 \\110 & 90 & 0
\end{bmatrix} \\[2em]
&= \begin{bmatrix}
112 + 101 & 86+89 & 0+1 \\ 134+110 & 94+90 & 0+0
\end{bmatrix} \\[2em]
&= \begin{bmatrix}
213 & 175 & 1 \\ 244 & 184 & 0
\end{bmatrix}
\end{split}
$$

In general, the elements in the summed matrix, **C**, are defined as $\mathbf{C}_{ij}=\mathbf{A}_{ij} + \mathbf{B}_{ij}$ for all *i* and *j*. Since subtraction is equivalent to adding the inverse, subtracting the elements of **B** from **A** is equivalent to adding the inverted elements of **B** to the elements of **A** (where "inverting the elements" means switching the sign on each element). 

$$
\begin{split}
\mathbf{A} - \mathbf{B} &= \begin{bmatrix}
112 & 86 & 0 \\ 134 & 94 & 0
\end{bmatrix} + \begin{bmatrix}
-101 & -89 & -1 \\-110 & -90 & 0
\end{bmatrix} \\[2em]
&= \begin{bmatrix}
11 & -3 & -1 \\ 24 & 4 & 0
\end{bmatrix}
\end{split}
$$

Computationally, we can use the `+` and `-` operators in R to add and subtract matrices.

```{r}
# Create A
A = matrix(data = c(112, 86, 0, 134, 94, 0), byrow = TRUE, nrow = 2)

# Create B
B = matrix(data = c(101, 89, 1, 110, 90, 0), byrow = TRUE, nrow = 2)

# Matrix addition
A + B

# Matrix Subtraction
A - B
```

<br /> 

### Properties of Matrix Addition


Matrix addition satisfies both the commutative and associative properties. That is,

$$
\mathbf{A} + \mathbf{B} = \mathbf{B} + \mathbf{A}
$$

and

$$
\begin{split}
\mathbf{A} + (\mathbf{B} + \mathbf{C}) &= (\mathbf{A} + \mathbf{B}) + \mathbf{C} \\[2ex]
&= \mathbf{A} + \mathbf{B} + \mathbf{C}
\end{split}
$$




<br />

### Deviation Matrix

We have seen that deviation scores are particularly useful in statistics. We can create a deviation matrix by taking a score matrix and subtracting from it a matrix of means, where each column contains the mean for each corresponding column in the original matrix, that is:

$$
\mathbf{D} = \mathbf{X} - \mathbf{M}
$$

For example, consider the following score matrix:

$$
\mathbf{X} = \begin{bmatrix}
3.0 & 11 & 112 \\ 3.9 & 10 & 143 \\ 2.9 & 19 & 124 \\ 2.7 & 7 & 129
\end{bmatrix}
$$
To compute the mean deviation matrix, **D** we use:


$$
\begin{split}
\mathbf{D} &= \mathbf{X} - \mathbf{M} \\[2em]
&= \begin{bmatrix}
3.0 & 11 & 112 \\ 3.9 & 10 & 143 \\ 2.9 & 19 & 124 \\ 2.7 & 7 & 129
\end{bmatrix} - \begin{bmatrix}
3.125 & 11.75 & 127 \\ 3.125 & 11.75 & 127 \\ 3.125 & 11.75 & 127 \\ 3.125 & 11.75 & 127
\end{bmatrix} \\[2em]
&= \begin{bmatrix}
-0.125 & -0.75 & -15 \\ 0.775 & -1.75 & 16 \\ -0.225 & 7.25 & -3 \\ -0.425 & -4.75 & 2
\end{bmatrix}
\end{split}
$$

Computationally, we can use the `colMeans()` function to compute the mean in each column of **X**. Then we can create matrix **M** by using the `rep()` function to repeat this set of means four times. (There are four rows in **M** that have the exact same elements.)

```{r}
# Create X
X = matrix(data = c(3.0, 11, 112, 3.9, 10, 143, 2.9, 19, 124, 2.7, 7, 129), byrow = TRUE, nrow = 4)
X

# Compute column means
colMeans(X)

# Create M
M = matrix(rep(colMeans(X), 4), byrow = TRUE, nrow =4)
M

# Compute deviation matrix
X - M
```

<br />

## Scalar--Matrix Multiplication

Any matrix can be multiplied by a scalar. The result is a matrix in which each element in the original matrix is multiplied by the value of the scalar. For example to multiply matrix **A** (from the previous section) by a scalar $\lambda = -2$,

$$
\begin{split}
-2\mathbf{A} &= -2\begin{bmatrix}
112 & 86 & 0 \\ 134 & 94 & 0
\end{bmatrix} \\[2em]
&= \begin{bmatrix}
-2(112) & -2(86) & -2(0) \\ -2(134) & -2(94) & -2(0)
\end{bmatrix} \\[2em]
&= \begin{bmatrix}
-224 & -172 & 0 \\ -268 & -188 & 0
\end{bmatrix}
\end{split}
$$
In general the elements of the product matrix, $\lambda\mathbf{A}$, are $\lambda (a_{ij})$ for every *i* and *j*. Scalar--matrix multiplication is commutative, that is:

$$
\lambda\mathbf{A} = \mathbf{A}\lambda
$$

In R we use the `*` operator to perform scalar--matrix multiplication.

```{r}
-2 * A
```

<br />


## Matrix Multiplication

The process of multiplying matrices follows the same basic principle as vector multiplication, where we consider matrices to be a collection of column vectors. When we multiply vectors, they must have the same number of elements because we multiply corresponding elements and add the resulting products, obtaining a scalar (dot) product (i.e., $\mathbf{a}\bullet\mathbf{b}$). To multiply matrix **X** by matrix **Y**, we are going to compute the dot product between each row in **X** and each column in **Y**, that is, $\mathbf{x}^\intercal_{j}\bullet\mathbf{b}_j$. As an example, consider the following two matrices:

$$
\mathbf{X} = \begin{bmatrix}
2 & 3 \\ 1 & 2 
\end{bmatrix} \qquad \mathbf{Y} = \begin{bmatrix}
5 & -2 \\ 4 & -1 
\end{bmatrix}
$$

To complete the multiplication of  **XY**, we compute the dot product between the first row of **X** and the first column of **Y** (i.e., $\mathbf{X}_1^\intercal\bullet\mathbf{Y}_1$).

$$
\begin{split}
\begin{bmatrix}2 & 3\end{bmatrix}\begin{bmatrix}5 \\ 4\end{bmatrix} &= 2(5) + 3(4)\\[2em]
&= 22
\end{split}
$$

This gives us the element in the first row and first column of the product matrix, **Z**. The element in the first row and second column of **Z** is based on the dot product between the the first row of **X** and the second column of **Y**. This continues, finding the dot product between rows of **X** and columns of **Y** for each corresponding element in **Z**.


$$
\begin{split}
\mathbf{Z} &= \begin{bmatrix}\begin{bmatrix}2 & 3\end{bmatrix}\begin{bmatrix}5 \\ 4\end{bmatrix} & \begin{bmatrix}2 & 3\end{bmatrix}\begin{bmatrix}-2 \\ -1\end{bmatrix} \\ \begin{bmatrix}1 & 2\end{bmatrix}\begin{bmatrix}5 \\ 4\end{bmatrix} & \begin{bmatrix}1 & 2\end{bmatrix}\begin{bmatrix}-2 \\ -1\end{bmatrix}\end{bmatrix}\\[2em]
&= \begin{bmatrix}
22 & -7 \\ 13 & -4 
\end{bmatrix}
\end{split}
$$

:::note
This process must always be carefully followed: Finding the dot product between a row of the first matrix and a column of the second matrix. The general rule on matrix multiplication for $\mathbf{AB} = \mathbf{C}$, for each element in **C**, $C_{ij}$ is the dot product of the *i*th row of **A** and the *j*th column of **B**.
:::

To compute the product between two matrices we use the matrix multiplication operator, `%*%`.

```{r}
# Create A
A = matrix(data = c(2, 3, 1, 2), byrow = TRUE, nrow = 2)

# Create B
B = matrix(data = c(5, -2, 4, -1), byrow = TRUE, nrow = 2)

# Matrix multiplication
A %*% B
```

In contrast to scalar multiplication, matrix multiplication is rarely commutative, that is, it is rare that $\mathbf{AB}=\mathbf{BA}$. In our previous example, $\mathbf{AB}\neq\mathbf{BA}$.

```{r}
# Matrix multiplication
B %*% A
```

The resulting product is not the same as computing **AB**. The order of the multiplication is quite important, so rather than saying that "**A** is multiplied by **B**", we instead specify the order by saying:

- **A** is *postmultiplied* by **B**; or
- **B** is *premultiplied* by **A**.


<br />

#### Conformability

We can also multiply matrices that are not of equal dimensions, as long as they are *conformable*.  To be conformable, the number of columns in the premultiplied (first) matrix must equal the number of rows in the postmultiplied (second) matrix. For example, matrices **A** and **B** (below) are conformable since the number of columns in **A** is equal to the number of rows in **B**, namely 4.

$$
\underset{2\times4}{\mathbf{A}} = \begin{bmatrix}
5 & 2 & 3 & 4 \\ 5 & 4 & 6 & 1
\end{bmatrix} \qquad \underset{4\times3}{\mathbf{B}} = \begin{bmatrix}
8 & 9 & 4 \\ 6 & 5 & 1 \\ 2 & 3 & 4 \\ 6 & 1 & 2 
\end{bmatrix}
$$

One way to consider conformability is to ensure that the *inner dimensions* of the two matrices being multiplied are equal. Here the inner dimensions (shown in red) are both 4. 

$$
\underset{2\times\color{red}{4}}{\mathbf{A}}~\underset{{\color{red}{4}} \times3}{\mathbf{B}}
$$

```{r}
# Create A
A = matrix(data = c(5, 2, 3, 4, 5, 4, 6, 1), byrow = TRUE, nrow = 2)

# Create B
B = matrix(data = c(8, 9, 4, 6, 5, 1, 2, 3, 4, 6, 1, 2), byrow = TRUE, nrow = 4)

# Postmultiply A by B
A %*% B
```

Notice the product **AB** has dimensions of $2\times4$, which are the *outer dimensions* shown in the product (below in red).

$$
\underset{{\color{red}{2}} \times4}{\mathbf{A}}~\underset{4\times\color{red}{3}}{\mathbf{B}}
$$


If we tried to postmultiply **B** by **A**, that product is not conformable since the inner dimensions would no longer match (i.e., $3\neq2$).

$$
\underset{4\times\color{red}{3}}{\mathbf{B}} ~ \underset{{\color{red}{2}}\times4}{\mathbf{A}}
$$

```{r error=TRUE}
# Postmultiply B by A
B %*% A
```


<br />

### Properties of Matrix Multiplication

Although matrix multiplication is rarely commutative, it does have the following properties:

- $\mathbf{A}(\mathbf{BC})=(\mathbf{AB})\mathbf{C})$ (Associative Property)
- $\mathbf{A}(\mathbf{B}+\mathbf{C})=\mathbf{AB} +\mathbf{AC})$ (Left Distributive Property)
- $(\mathbf{B}+\mathbf{C})\mathbf{A}=\mathbf{BA} +\mathbf{CA})$ (Right Distributive Property)

so long as the matrices being considered are conformable. 

Aside from commutativity, there are also some other properties that matrix multiplication lack. For example, in scalar arithmetic, if $ab = 0$, then either *a* or *b* must be zero. In matrix multiplication, however, this is not always the case. To illustrate, consider the following three matrices:

$$
\mathbf{A} = \begin{bmatrix}-2 & 4 \\-2 & 4 \end{bmatrix} \qquad \mathbf{B} = \begin{bmatrix}0 & 0 \\0 & 0 \end{bmatrix} \qquad \mathbf{C} = \begin{bmatrix}4 & 4 \\2 & 2 \end{bmatrix} 
$$

Matrix **B**, in which every element is zero is called the *null matrix*. (A null matrix is a matrix in which every element is zero.) If we postmultiply matrix **A** by the null matrix **B**, we get:

$$
\begin{split}
\mathbf{A}\mathbf{B} &= \begin{bmatrix}-2 & 4 \\-2 & 4 \end{bmatrix} \begin{bmatrix}0 & 0 \\0 & 0 \end{bmatrix} \\[2em]
&= \begin{bmatrix}0 & 0 \\0 & 0 \end{bmatrix}
\end{split}
$$

The result of postmultiplying a matrix (so long as it is conformable) by the null matrix is a null matrix. This is also true when we premultiply by a null matrix.  Now consider postmultiplying matrix **A** by matrix **C**:

$$
\begin{split}
\mathbf{A}\mathbf{C} &= \begin{bmatrix}-2 & 4 \\-2 & 4 \end{bmatrix} \begin{bmatrix}4 & 4 \\2 & 2 \end{bmatrix} \\[2em]
&= \begin{bmatrix}0 & 0 \\0 & 0 \end{bmatrix}
\end{split}
$$

We again obtain a null matrix. However, neither **A** nor **C** was a null matrix. (In fact, none of the elements of **A** or **C** were zero).


Relatedly, in scalar arithmetic, if $ab = 0$, then $ba = 0$. This property does not hold in matrix multiplication. For example, we just saw that $\mathbf{A}\mathbf{C}=\mathbf{0}$. But, if we postmultiply **C** by **A**:

$$
\begin{split}
\mathbf{C}\mathbf{A} &=  \begin{bmatrix}4 & 4 \\2 & 2 \end{bmatrix}\begin{bmatrix}-2 & 4 \\-2 & 4 \end{bmatrix} \\[2em]
&= \begin{bmatrix}-16 & 16 \\-8 & 8 \end{bmatrix}
\end{split}
$$

That is, although $\mathbf{A}\mathbf{C}=\mathbf{0}$, $\mathbf{C}\mathbf{A}\neq\mathbf{0}$. Changing the order of the matrix multiplication changes the resulting product.

Drawing from this example we see that since $\mathbf{AB}=\mathbf{0}$ and $\mathbf{AC}=\mathbf{0}$, this means that $\mathbf{AB}=\mathbf{AC}$. However, $\mathbf{B}\neq\mathbf{C}$. This implies that "cancellation" is not a valid property of matrix multiplication.

<br />

### Revisiting Dot Products

It turns out that we can express the dot product between two vectors as matrix multiplication. Consider the column vectors **a** and **b**:

$$
\mathbf{a} = \begin{bmatrix}5 \\ 4 \\ 7 \\ 2\end{bmatrix} \qquad \mathbf{b} = \begin{bmatrix}1 \\ 0 \\ -1 \\ 2\end{bmatrix}
$$

Remember column vectors are matrices with one column. The dot product between **a** and **b** is the same as premultiplying **b** by the transpose of **a**, that is:

$$
\mathbf{a}\bullet\mathbf{b} = \underset{1\times4}{\mathbf{a}^\intercal}~\underset{4\times1}{\mathbf{b}}
$$

By transposing **a**, the matrices are conformable, and the resulting product will be a $1\times1$ matrix (i.e., a scalar).

```{r}
# Create a
a = matrix(data = c(5, 4, 7, 2), ncol = 1)

# Create b
b = matrix(data = c(1, 0, -1, 2), ncol = 1)

# Postmultiply the transpose of a by b
t(a) %*% b

# Compute dot product as sum of products
sum(a * b)
```


<br />

:::exercises
### Exercises

**Consider the following matrices:**

$$
\mathbf{X} = \begin{bmatrix}2 & 3 \\1 & 2 \end{bmatrix} \qquad \mathbf{Y} = \begin{bmatrix}3 & 4 \\2 & 1 \end{bmatrix} \qquad \mathbf{Z} = \begin{bmatrix}2 & 3 & 1 \\5 & 6 & 8\\9 & 4 & 7 \end{bmatrix}
$$

1. Find $\mathbf{X} + \mathbf{Y}$.

<button class="solution-btn solution-btn-default" onclick="toggle_visibility('solution_01');">Show/Hide Solution</button>
<div id="solution_01" style="display:none; margin: -40px 0 40px 40px;">
$$
\begin{split}
\mathbf{X}+\mathbf{Y} &= \begin{bmatrix}2+3 & 3+4 \\1+2 & 2+1 \end{bmatrix} \\[1em]
&= \begin{bmatrix}5 & 7 \\3 & 3 \end{bmatrix}
\end{split}
$$
</div>

2. Find $\mathbf{X} - \mathbf{Y}$.

<button class="solution-btn solution-btn-default" onclick="toggle_visibility('solution_02');">Show/Hide Solution</button>
<div id="solution_02" style="display:none; margin: -40px 0 40px 40px;">
$$
\begin{split}
\mathbf{X}-\mathbf{Y} &= \begin{bmatrix}2-3 & 3-4 \\1-2 & 2-1 \end{bmatrix} \\[1em]
&= \begin{bmatrix}-1 & -1 \\-1 & 1 \end{bmatrix}
\end{split}
$$
</div>

3. Find $3 \mathbf{Z}$.

<button class="solution-btn solution-btn-default" onclick="toggle_visibility('solution_03');">Show/Hide Solution</button>
<div id="solution_03" style="display:none; margin: -40px 0 40px 40px;">
$$
\begin{split}
3\mathbf{Z} &= \begin{bmatrix}3(2) & 3(3) & 3(1) \\3(5) & 3(6) & 3(8)\\3(9) & 3(4) & 3(7) \end{bmatrix} \\[1em]
&= \begin{bmatrix}6 & 9 & 3 \\15 & 18 & 24\\27 & 12 & 21 \end{bmatrix}
\end{split}
$$
</div>

4. Find $-2 \mathbf{X} + 4\mathbf{Y}$.

<button class="solution-btn solution-btn-default" onclick="toggle_visibility('solution_04');">Show/Hide Solution</button>
<div id="solution_04" style="display:none; margin: -40px 0 40px 40px;">

$$
\begin{split}
-2\mathbf{X}+4\mathbf{Y} &= \begin{bmatrix}-2(2)+4(3) & -2(3)+4(4) \\-2(1)+4(2) & -2(2)+4(1) \end{bmatrix} \\[1em]
&= \begin{bmatrix}8 & 10 \\6 & 0 \end{bmatrix}
\end{split}
$$

</div>

**Consider the following matrices:**

$$
\mathbf{A} = \begin{bmatrix}0 & 6 \\5 & 1 \end{bmatrix} \qquad \mathbf{B} = \begin{bmatrix}0 & 5 \\2 & \frac{1}{2} \end{bmatrix} \qquad \mathbf{C} = \begin{bmatrix}6 & 2 & 1 \\5 & 3 & 1\\8 & 4 & 1 \end{bmatrix} \qquad \mathbf{D} = \begin{bmatrix}0& 1 & 4 & 6 \\1 & 2 & 5 & -2\\1 & 3 & 2 & 8 \end{bmatrix}
$$

5. Is **AB** conformable?

<button class="solution-btn solution-btn-default" onclick="toggle_visibility('solution_05');">Show/Hide Solution</button>
<div id="solution_05" style="display:none; margin: -40px 0 40px 40px;">

Yes. Since **A** has two columns and **B** has the same number of rows, **AB** is conformable.

$$
\underset{2\times\color{red}{2}}{\mathbf{A}}~\underset{{\color{red}{2}} \times2}{\mathbf{B}}
$$

</div>

6. Is **BC** conformable?

<button class="solution-btn solution-btn-default" onclick="toggle_visibility('solution_06');">Show/Hide Solution</button>
<div id="solution_06" style="display:none; margin: -40px 0 40px 40px;">

No. Since **B** has two columns and **C** has three rows, **BC** is not conformable.

$$
\underset{2\times\color{red}{2}}{\mathbf{B}}~\underset{{\color{red}{3}} \times3}{\mathbf{C}}
$$

</div>



7. Is the product where we premultiply **D** by **C** conformable?

<button class="solution-btn solution-btn-default" onclick="toggle_visibility('solution_07');">Show/Hide Solution</button>
<div id="solution_07" style="display:none; margin: -40px 0 40px 40px;">

Yes. Since **C** has three columns and **D** has the same number of rows, **CD** is conformable.

$$
\underset{3\times\color{red}{3}}{\mathbf{C}}~\underset{{\color{red}{3}} \times4}{\mathbf{D}}
$$

</div>

**Statistics Example: Weights**

8. Consider the scores for five students on four course exams (each out of 100 points) shown in matrix **X**. The final percentage in the course is based on the following weighting: the first and second exams are worth 10% of the course, the third exam is worth 30% of the course, and the fourth exam is worth 50% of the course. These weights are presented in the column vector **w**. Use R to find the final percentage for each student by postmultiplying the score matrix by the weight vector.

$$
\mathbf{X} = \begin{bmatrix}32 & 54 & 56 & 21 \\42 & 23 & 52 & 35 \\ 16 & 41 & 54 & 56 \\ 58 & 52 & 31 & 24 \\ 41 & 50 & 42 & 40 \end{bmatrix} \qquad \mathbf{w} = \begin{bmatrix} 0.10 \\ 0.10 \\ 0.30 \\ 0.50 \end{bmatrix}
$$



<button class="solution-btn solution-btn-default" onclick="toggle_visibility('solution_10');">Show/Hide Solution</button>
<div id="solution_10" style="display:none; margin: -40px 0 40px 40px;">

```{r}
# Create X
X = matrix(
  data = c(32, 54, 56, 21,
           42, 23, 52, 35,
           16, 41, 54, 56,
           58, 52, 31, 24,
           41, 50, 42, 40),
  byrow = TRUE, 
  ncol = 4
)

# Create w
w = matrix(data = c(0.10, 0.10, 0.30, 0.50), ncol = 1)

# Compute Xw
X %*% w
```


</div>


:::



<br />

